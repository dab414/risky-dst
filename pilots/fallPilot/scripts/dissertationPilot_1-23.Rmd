---
title: "Dissertation Pilot 1"
output: 
  html_document:
    code_folding: hide
---
## Assessing effort demand across different likelihoods of switching tasks.
The purpose of this document is to anaylze the first pilot for my dissertation, the data for which was collected in the Fall of 2018.  

In short, participants were presented with many blocks of short runs (i.e., 16 trials) of cued task switching. The probability that each trial in the run would be a task switch was manipulated (between .1 and 1, in intervals of .1) between blocks.  

With this document, I'm investigating both total run time and average trial RT as a function of probability of task switch. The prediction is that both of these outcomes will increase as a function of p(switch). However, it's possible that, as the likelihood of switching approaches certain (i.e., 1), responding actually becomes *easier*, and outcomes will decrease.

```{r include = FALSE}
library(tidyverse)
library(DT)
```

```{r include = FALSE}
df <- read.csv('../data/dissertationPilot.csv')
rows <- nrow(df)
```

A table with only the first 10,000 of `r rows` rows of the data.

```{r}
datatable(df[1:10000,], filter = 'top', options = list(pageLength = 5, autoWidth = TRUE))
```


Sample size is:
```{r}
df %>% 
  group_by(subject) %>% 
  summarize(n()) %>% 
  nrow()
```


A quick look at the RT and error distribution:

```{r echo = FALSE}
df %>% 
  ggplot(aes(x = rt)) + geom_histogram(fill = 'blue', alpha = .6)

df %>% 
  group_by(subject) %>% 
  summarize(errorRate = mean(error)) %>% 
  ggplot(aes(x = reorder(subject, -errorRate), y = errorRate)) + geom_bar(stat='identity') + ylab('Error Rate') + xlab('Subject')
```

### Total run time
This will really just be summing all rts within a run by participants and then averaging across participants.

```{r echo = FALSE}
df %>% 
  filter(errortrim == 0) %>% 
  group_by(subject, pSwitch) %>% 
  summarize(sRt = sum(rt)) %>% 
  group_by(pSwitch) %>% 
  summarize(sumRt = mean(sRt) / 1000, se = (sd(sRt) / sqrt(n())) / 1000) %>% 
  ggplot(aes(x = as.factor(pSwitch), y = sumRt, group = 1)) + geom_line(size = 2) + xlab('Probability of Switching in a Run') + ylab('Mean Run time (s)') + geom_ribbon(aes(ymin = sumRt - se, ymax = sumRt + se), alpha = .3)
```

Looks pretty monotonic to me. Next up is average RT per trial.

### Average RT

Calculating the average RT per p(switch) per participant and then averaging across participants.

```{r echo = FALSE}
df %>% 
  filter(errortrim == 0) %>% 
  group_by(subject, pSwitch) %>% 
  summarize(rt = mean(rt)) %>% 
  group_by(pSwitch) %>% 
  summarize(rTime = mean(rt), se = sd(rt) / sqrt(n())) %>% 
  ggplot(aes(x = factor(pSwitch), y = rTime, group = 1)) + geom_line(size = 2) + xlab('Probability of Switching in a Run') + ylab('Mean RT (ms)') + geom_ribbon(aes(ymin = rTime - se, ymax = rTime + se), alpha = .3)
```

Still mostly monotonic. If anything we're seeing the only decrease in time (and, in the case of total run time, it stays pretty much the same) from 0.9 to 1. So I think we're pretty safe using 0.8 or 0.9 as high demand levels of switching.  

Now I'm doing the same but for errors

## Error Rates

### Total errors across a run
Summing errors within a run by participant and then averaging across participants


```{r}
df %>% 
  group_by(subject, pSwitch) %>% 
  summarize(eRate = sum(error)) %>% 
  group_by(pSwitch) %>% 
  summarize(errorRate = mean(eRate) / 1000, se = (sd(eRate) / sqrt(n())) / 1000) %>% 
  ggplot(aes(x = as.factor(pSwitch), y = errorRate, group = 1)) + geom_line(size = 2) + xlab('Probability of Switching in a Run') + ylab('Mean Error Rate') + geom_ribbon(aes(ymin = errorRate - se, ymax = errorRate + se), alpha = .3)
```

Interesting, this tells a slightly different story from the RTs.. at least with respect to the difference between 0.9 and 1.  

### Average errors per run
Taking the average number of errors per participant per switch condition and then averaging across participants

```{r}
df %>% 
  group_by(subject, pSwitch) %>% 
  summarize(eRate = mean(error)) %>% 
  group_by(pSwitch) %>% 
  summarize(errorRate = mean(eRate), se = sd(eRate) / sqrt(n())) %>% 
  ggplot(aes(x = factor(pSwitch), y = errorRate, group = 1)) + geom_line(size = 2) + xlab('Probability of Switching in a Run') + ylab('Mean Error Rate') + geom_ribbon(aes(ymin = errorRate - se, ymax = errorRate + se), alpha = .3)
```


Pretty much the same idea as total number of errors per run.  

Let's put an RT graph together with an error graph to use as a figure for the document.

```{r}
graphData <- df %>% 
  filter(errortrim == 0) %>% 
  group_by(subject, pSwitch) %>% 
  summarize(rt = mean(rt)) %>% 
  group_by(pSwitch) %>% 
  summarize(rTime = mean(rt), se = sd(rt) / sqrt(n())) 

graphData <- df %>% 
  group_by(subject, pSwitch) %>% 
  summarize(eRate = mean(error)) %>% 
  group_by(pSwitch) %>% 
  summarize(errorRate = mean(eRate), se = sd(eRate) / sqrt(n())) %>% 
  inner_join(graphData, by = 'pSwitch') %>% 
  gather(variable, value, errorRate, rTime) %>% 
  mutate(se = ifelse(variable == 'errorRate', se.x, se.y)) %>% 
  select(-se.x, -se.y)

graphData$variable <- factor(graphData$variable)
levels(graphData$variable) <- c('Mean Error Rate', 'Mean Response Time (ms)')


ggplot(graphData, aes(x = pSwitch, y = value, group = 1)) + geom_line() + geom_point(size = 2) + 
  geom_errorbar(aes(ymax = value + se, ymin = value - se)) + 
  #geom_ribbon(aes(ymax = value + se, ymin = value - se), alpha = .2) + 
  facet_wrap(~variable, scales = 'free') + 
  xlab('Probability of Switching in a Run') + theme_bw() + 
  scale_x_continuous(breaks = seq(0,1,0.2)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        strip.background = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks = element_blank(),
        text = element_text(size = 15))
  
ggsave('pilotSummary.png', height = 5.5, width = 7.5, units = 'in', dpi = 300)
```



















